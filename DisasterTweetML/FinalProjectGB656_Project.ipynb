{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "import nltk\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYXvAAzDUPch",
        "outputId": "cf50ff5b-2c78-49dc-9ba3-a4b613dc8018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test (1).csv')"
      ],
      "metadata": {
        "id": "rkMzMjxVUP4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])\n",
        "    return text"
      ],
      "metadata": {
        "id": "YH0PEc_uUWCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply preprocessing\n",
        "train_df['cleaned_text'] = train_df['text'].apply(preprocess_text)\n",
        "test_df['cleaned_text'] = test_df['text'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "Y3Y-dPwLUcbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values in 'keyword' and 'location'\n",
        "train_df['keyword'] = train_df['keyword'].fillna('none')\n",
        "test_df['keyword'] = test_df['keyword'].fillna('none')"
      ],
      "metadata": {
        "id": "x0dEOelhUeoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine 'keyword' and 'cleaned_text'\n",
        "train_df['combined_text'] = train_df['keyword'] + ' ' + train_df['cleaned_text']\n",
        "test_df['combined_text'] = test_df['keyword'] + ' ' + test_df['cleaned_text']"
      ],
      "metadata": {
        "id": "eiMK9EOlUgQM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "74471df4-13d0-4b48-bec9-b7af273ce92a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-21d7406558e0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Combine 'keyword' and 'cleaned_text'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'combined_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keyword'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleaned_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'combined_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keyword'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleaned_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features and target\n",
        "X = train_df['combined_text']\n",
        "y = train_df['target']"
      ],
      "metadata": {
        "id": "3Ewrv_l-Uh6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "g_xYaPueUjXU",
        "outputId": "1b726575-e875-4ca6-eeee-e414842fb1be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      none deed reason earthquake may allah forgive u\n",
              "1           none forest fire near la ronge sask canada\n",
              "2    none resident asked shelter place notified off...\n",
              "3    none people receive wildfire evacuation order ...\n",
              "4    none got sent photo ruby alaska smoke wildfire...\n",
              "Name: combined_text, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>combined_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>none deed reason earthquake may allah forgive u</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>none forest fire near la ronge sask canada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>none resident asked shelter place notified off...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>none people receive wildfire evacuation order ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>none got sent photo ruby alaska smoke wildfire...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "SRDVgm_qUmJx",
        "outputId": "04031b65-1334-4a39-9a86-3131d01033c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1\n",
              "1    1\n",
              "2    1\n",
              "3    1\n",
              "4    1\n",
              "Name: target, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "DFTxv_d4Mbmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=500, random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'Support Vector Machine': SVC(kernel='linear', random_state=42)\n",
        "}"
      ],
      "metadata": {
        "id": "kxjP-b9vUoGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning for Logistic Regression\n",
        "param_grid = {\n",
        "    'clf__C': [0.01, 0.1, 1, 10],\n",
        "    'clf__penalty': ['l2'],\n",
        "    'tfidf__max_features': [5000, 10000, 20000],\n",
        "    'tfidf__ngram_range': [(1, 1), (1, 2)]\n",
        "}"
      ],
      "metadata": {
        "id": "n0VdOCVPVA0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate models\n",
        "def train_and_evaluate():\n",
        "    best_pipeline = None\n",
        "    best_model_name = ''\n",
        "    best_accuracy = 0\n",
        "\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\nTraining {name}...\")\n",
        "        pipeline = Pipeline([\n",
        "            ('tfidf', TfidfVectorizer()),\n",
        "            ('clf', model)\n",
        "        ])\n",
        "        if name == 'Logistic Regression':\n",
        "            grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "            grid_search.fit(X_train, y_train)\n",
        "            best_pipeline = grid_search.best_estimator_\n",
        "            print(\"Best Params:\", grid_search.best_params_)\n",
        "        else:\n",
        "            pipeline.fit(X_train, y_train)\n",
        "            best_pipeline = pipeline\n",
        "\n",
        "        y_val_pred = best_pipeline.predict(X_val)\n",
        "        accuracy = accuracy_score(y_val, y_val_pred)\n",
        "        print(f\"{name} Accuracy: {accuracy:.2%}\")\n",
        "        print(f\"Classification Report for {name}:\\n\", classification_report(y_val, y_val_pred))\n",
        "\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_model_name = name\n",
        "\n",
        "    print(f\"\\nBest Model: {best_model_name} with Accuracy: {best_accuracy:.2%}\")\n",
        "    return best_pipeline\n",
        "\n",
        "best_pipeline = train_and_evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aO2S5H_6Up1O",
        "outputId": "19e3a5f2-1d7b-4a2b-8346-0cb8e18c9d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Logistic Regression...\n",
            "Best Params: {'clf__C': 1, 'clf__penalty': 'l2', 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1)}\n",
            "Logistic Regression Accuracy: 81.55%\n",
            "Classification Report for Logistic Regression:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.89      0.85       869\n",
            "           1       0.83      0.72      0.77       654\n",
            "\n",
            "    accuracy                           0.82      1523\n",
            "   macro avg       0.82      0.80      0.81      1523\n",
            "weighted avg       0.82      0.82      0.81      1523\n",
            "\n",
            "\n",
            "Training Random Forest...\n",
            "Random Forest Accuracy: 78.79%\n",
            "Classification Report for Random Forest:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.91      0.83       869\n",
            "           1       0.84      0.63      0.72       654\n",
            "\n",
            "    accuracy                           0.79      1523\n",
            "   macro avg       0.80      0.77      0.77      1523\n",
            "weighted avg       0.80      0.79      0.78      1523\n",
            "\n",
            "\n",
            "Training Support Vector Machine...\n",
            "Support Vector Machine Accuracy: 82.07%\n",
            "Classification Report for Support Vector Machine:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.88      0.85       869\n",
            "           1       0.83      0.74      0.78       654\n",
            "\n",
            "    accuracy                           0.82      1523\n",
            "   macro avg       0.82      0.81      0.81      1523\n",
            "weighted avg       0.82      0.82      0.82      1523\n",
            "\n",
            "\n",
            "Best Model: Support Vector Machine with Accuracy: 82.07%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "test_df['predictions'] = best_pipeline.predict(test_df['combined_text'])"
      ],
      "metadata": {
        "id": "WJuR-CtvVVU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_df[['id', 'combined_text', 'predictions']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4W4WtyoTWPzm",
        "outputId": "abb9e7e4-9951-4232-d340-9bfe3b0ccff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id                                      combined_text  predictions\n",
            "0   0                   none happened terrible car crash            0\n",
            "1   2  none heard earthquake different city stay safe...            1\n",
            "2   3  none forest fire spot pond goose fleeing acros...            1\n",
            "3   9          none apocalypse lighting spokane wildfire            1\n",
            "4  11            none typhoon soudelor kill china taiwan            1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save submission\n",
        "sample_submission = pd.read_csv('sample_submission.csv')\n",
        "sample_submission['target'] = test_df['predictions']\n",
        "submission_path = 'disaster_predictions_submission.csv'\n",
        "sample_submission.to_csv(submission_path, index=False)\n",
        "print(f\"Submission file saved to {submission_path}\")"
      ],
      "metadata": {
        "id": "kvmbe3OmVVmD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}